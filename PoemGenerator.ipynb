{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc2e874",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ashrafwkhalil/NN-Poetry-Generator/blob/main/PoemGenerator.ipynb#scrollTo=cba778ac\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a633e",
   "metadata": {},
   "source": [
    "# Poem Generator\n",
    "I will create a Poem Generator by training a neural network to predict the next word given an input sequence of words, and then using that model to continuously generate text. The model will be trained on a large dataset of poems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98676ad7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae36ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8b14c",
   "metadata": {},
   "source": [
    "Here I will be downloading the entire github repo so that I can access all neccessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone 'https://github.com/ashrafwkhalil/NN-Poetry-Generator.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802e1dd",
   "metadata": {},
   "source": [
    "## Organize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d90fca",
   "metadata": {},
   "source": [
    "In the below cell, I will be formatting my poem data into just lines of text with some maximum length, measured in number of words. I have stored the max line length value as a variable, thus allowing me to use it almost as a hyperparameter, as I am able to modify it and compare model performance with different values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c1e892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Grownups in the house \\n', 'Haunt responsibilities \\n',\n",
       "       'I watch dream T V \\n', 'Jet powered action \\n',\n",
       "       'Kids save their town from monsters \\n', 'Lunatics and thugs \\n',\n",
       "       'Mountains streak below \\n', 'New character friend or foe \\n',\n",
       "       'Only time will tell \\n', 'Preview of  next show \\n',\n",
       "       'Queen of dream sends champion \\n', 'Racing with Jet Kids \\n',\n",
       "       'Saving the future \\n', 'Tune in tom arrow and see \\n',\n",
       "       'Ultimate showdown \\n', 'Victory assured \\n',\n",
       "       'Waving heroes, credits roll \\n', 'X factor revealed \\n',\n",
       "       'Youthful television dream \\n', \"Zooms away, I'm still asleep \\n\",\n",
       "       '- + \\n', 'Almost awake view \\n', 'Banished from reality \\n',\n",
       "       'Creature made of mind \\n', 'Dream-scape citizen \\n',\n",
       "       'Everado Man-Shaped-Wind \\n', 'Face another day \\n',\n",
       "       'Grasp February \\n', 'Handle your business in the \\n',\n",
       "       'Indigo yonder', 'Love Returns (Oulipo Poetry R+7) \\n',\n",
       "       'January 25, 2020 \\n', 'Love \\n', 'Tender, \\n', 'Found wonder \\n',\n",
       "       'Who is in it, \\n', 'Found tender in heart; \\n',\n",
       "       'As I love my Great Lord, \\n', 'My Lord shows me the right path.',\n",
       "       'I got to ‘A’ and was assaulted and abused \\n',\n",
       "       'And attacked and ambushed and anger was used \\n',\n",
       "       'And acute agony left me anxious and bemused \\n',\n",
       "       'Then went to ‘B’ and got bloodied and battered \\n',\n",
       "       'And burnt and bashed and bruises were scattered \\n',\n",
       "       'And beaten and bones were broken and shattered \\n',\n",
       "       'I then gave up when a friend told me \\n',\n",
       "       'Worse things happen at ‘C’',\n",
       "       '(Ode To March, The Month Of Independence - An Horatian Ode) \\n',\n",
       "       'March, again you have come \\n',\n",
       "       'Holding the history from 1971, \\n'], dtype='<U2177')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Poems list\n",
    "poems = []\n",
    "# Poems here are stored in many different directories, I am going to iterate through all the different directories\n",
    "# and simply append all poems to the same list. This may be problematic, given that all of these directories represent\n",
    "# different styles of poems, but I will overlook that for this demo.\n",
    "forms_poems_path = '.NN-Poetry-Generator/Poems/forms'\n",
    "topics_poems_path = '.NN-Poetry-Generator/Poems/topics'\n",
    "directories_forms = os.listdir(forms_poems_path)\n",
    "directories_topics = os.listdir(topics_poems_path)\n",
    "# iterating through all directories\n",
    "for poem_form in directories_forms:\n",
    "    try:\n",
    "        for poem_file in os.listdir(os.path.join(forms_poems_path, poem_form)):\n",
    "            with open(os.path.join(forms_poems_path, poem_form, poem_file)) as poem:\n",
    "                lines = poem.readlines()\n",
    "                lines_newline_spaced = []\n",
    "                for line in lines:\n",
    "                    line = line.replace('\\n', ' \\n')\n",
    "                    lines_newline_spaced.append(line)\n",
    "                poems.append(lines_newline_spaced)[1:-1]\n",
    "    except:\n",
    "        continue\n",
    "for poem_form in directories_topics:\n",
    "    try:\n",
    "        for poem_file in os.listdir(os.path.join(topics_poems_path, poem_form)):\n",
    "            with open(os.path.join(topics_poems_path, poem_form, poem_file)) as poem:\n",
    "                lines = poem.readlines()\n",
    "                lines_newline_spaced = []\n",
    "                for line in lines:\n",
    "                    line = line.replace('\\n', ' \\n')\n",
    "                    lines_newline_spaced.append(line)\n",
    "                poems.append(lines_newline_spaced)[1:-1]\n",
    "    except:\n",
    "        continue\n",
    "# the max_line_length variable. This will decide what the maximum length of a single input into the model will be. \n",
    "# Any line above the max line length will be split up into separate elements, and these elements will be inserted \n",
    "# into the array\n",
    "max_line_length = 20\n",
    "poems = np.concatenate(poems)\n",
    "for i, line in enumerate(poems):\n",
    "    # split into arrays of words\n",
    "    line = line.split(' ')\n",
    "    if len(line) > max_line_length:\n",
    "        # add first maxlinelength sized chunk into array at original index\n",
    "        poems[i] = ' '.join(line[:max_line_length])\n",
    "        #split iterate through chunks of max line length\n",
    "        for x in range(1, int(len(line)/max_line_length)):\n",
    "            #insert chunks into poem list\n",
    "            np.insert(poems, i+x, ' '.join(line[max_line_length*(i):max_line_length*(i+1)]))\n",
    "poems[95:145]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148a7e9",
   "metadata": {},
   "source": [
    "## Tokenizing the inputs\n",
    "Here, I will tokenize all the inputs, convert them into tokenized sequences, then break down a single sequence into multiple. I will do this by repeatedly removing a word from the end of the sequence and using this new sequence, with the last word removed, as a separate sequence. The minimum size for a sequence at this stage will be 2 words long. In the next step, I will use the last word in a given sequence as the label for that sequence, thus making it so at least 2 words is necessary. I also add sequences of less than 4 words multiple times, being that I want the model to focus on ensuring that the words it predicts are as likely as possible to be grammatically correct, and words closest to the predicted word matter the most, at least that makes sense to me intuitively. There are other ways to do this, but through some trial and error, this actually gave not bad results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d6144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a tokenizer\n",
    "tokenizer = Tokenizer(filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t')\n",
    "tokenizer.fit_on_texts(poems)\n",
    "total_words = len(tokenizer.word_index)\n",
    "input_sequences = []\n",
    "# iterate through list of lines\n",
    "yy = 0\n",
    "for line in poems:\n",
    "    if yy > 20:\n",
    "        break\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    # keep adding in order subsets of the sequence that start at index 0 as separate sequences.\n",
    "    x = 0\n",
    "    for i in range(1, len(token_list)):\n",
    "        if i < 4:\n",
    "            y = 3\n",
    "        else:\n",
    "            y = 1\n",
    "        for x in range(y):\n",
    "            sequence = token_list[:i+1]\n",
    "            input_sequences.append(sequence)\n",
    "sequence_lengths = [len(x) for x in input_sequences]\n",
    "max_sequence_len = max(sequence_lengths)\n",
    "avg_sequence_len = np.array(sequence_lengths).mean()\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "# shuffle just in case\n",
    "np.random.shuffle(padded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb2a92c",
   "metadata": {},
   "source": [
    "## Creating Features and Labels\n",
    "Here I will take the last element of each sequence and use it as the label for that sequence. I will then convert the labels into one hot vectors. Remember, this model is going to be trained to predict the next word given an input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ea3707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    3,   11,    6],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,   15],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    8,    2, 2700, 1003],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    6, 1243,   13],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    2,  520,   66],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,  418, 2709,  419],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   15,   97,\n",
       "          19,  156,    5,  265,   50,  356, 6906,    4,    2,  111],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    7,  207,  171],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0, 4394],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,  234,   59,   39]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = padded_sequences[:, :-1]\n",
    "labels = padded_sequences[:, -1]\n",
    "one_hot_labels = to_categorical(labels, num_classes = total_words+1)\n",
    "features[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f11c0",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "Here, I will construct my model. Because the order of words in an input sequence are extremely important, I will use two adjacent  Bidirectional LSTM layers after my embedding layer. I will apply no convolutions to the inputs before these LSTMs, being that since I am trying to focus on the output being grammatically correct, ensuring the word-to-word integrity of the inputs into the initial LSTM is important. I will then convolve the outputs of the initial set of LSTMs with a size 3 filter, trying to extract possible patterns of adjacent word-groups of size 3. Then I will pass that into a final unidirectional LSTM. There will be 2 final dense layers, the final layer will have a single 'neuron' for each possible output word, and will have a softmax activation, as we are expecting a single discrete output: the word that we are guessing will be next in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d32f5a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 19:04:56.440980: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 21, 100)           826400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 21, 96)           57216     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 21, 96)           55680     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 19, 24)            6936      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 24)                4704      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8264)              4239432   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,203,168\n",
      "Trainable params: 5,203,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words+1, 100, input_length=max_sequence_len-1),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(48, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(48, return_sequences = True)),\n",
    "    tf.keras.layers.Conv1D(24, 3),\n",
    "    tf.keras.layers.LSTM(24),\n",
    "    tf.keras.layers.Dense(512, activation = 'sigmoid'),\n",
    "    tf.keras.layers.Dense(total_words+1, activation = 'softmax')\n",
    "])\n",
    "tf.keras.backend.clear_session()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62114991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "history = model.fit(features, one_hot_labels, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a3d95",
   "metadata": {},
   "source": [
    "Here is where you can choose an input seed that the NN can begin generating text based on. There is a pre-trained version of the model included in the repo, and the code directly below this will load it and use it to demo the poem generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba778ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = tf.keras.models.load_model('trained_model')\n",
    "# modify this how you like\n",
    "seed_text = \"Run into the wind\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\t# Convert the text into sequences\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\t# Pad the sequences\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\t# Get the probabilities of predicting a word\n",
    "\tpredicted = model_saved.predict(token_list, verbose=0)\n",
    "\t# Choose the next word based on the maximum probability\n",
    "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
    "\t# Get the actual word from the word index\n",
    "\toutput_word = tokenizer.index_word[predicted]\n",
    "    # Append to the current text\n",
    "\tseed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc1b947dce198ff7f2d2cb152b2cbb61132fce4429fa808fd5b89ac4d7df39fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
